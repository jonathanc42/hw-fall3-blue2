{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter grid search with xgboost\n",
    "#feature engineering is not so useful and the LB is so overfitted/underfitted\n",
    "#so it is good to trust your CV\n",
    "\n",
    "#go xgboost, go mxnet, go DMLC! http://dmlc.ml \n",
    "\n",
    "#Credit to Shize's R code and the python re-implementation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.cross_validation import *\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "\n",
    "train = train.drop('QuoteNumber', axis=1) \n",
    "test = test.drop('QuoteNumber', axis=1)\n",
    "\n",
    "# Lets play with some dates\n",
    "train['Date'] = pd.to_datetime(pd.Series(train['Original_Quote_Date']))\n",
    "train = train.drop('Original_Quote_Date', axis=1)\n",
    "\n",
    "test['Date'] = pd.to_datetime(pd.Series(test['Original_Quote_Date']))\n",
    "test = test.drop('Original_Quote_Date', axis=1)\n",
    "\n",
    "train['Year'] = train['Date'].apply(lambda x: int(str(x)[:4]))\n",
    "train['Month'] = train['Date'].apply(lambda x: int(str(x)[5:7]))\n",
    "train['weekday'] = train['Date'].dt.dayofweek\n",
    "\n",
    "test['Year'] = test['Date'].apply(lambda x: int(str(x)[:4]))\n",
    "test['Month'] = test['Date'].apply(lambda x: int(str(x)[5:7]))\n",
    "test['weekday'] = test['Date'].dt.dayofweek\n",
    "\n",
    "train = train.drop('Date', axis=1)  \n",
    "test = test.drop('Date', axis=1)\n",
    "\n",
    "#fill -999 to NAs\n",
    "train = train.fillna(-999)\n",
    "test = test.fillna(-999) \n",
    "\n",
    "features = list(train.columns[1:])  #la colonne 0 est le quote_conversionflag  \n",
    "print(features)\n",
    "\n",
    "\n",
    "for f in train.columns:\n",
    "    if train[f].dtype=='object':\n",
    "        print(f)\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(train[f].values) + list(test[f].values))\n",
    "        train[f] = lbl.transform(list(train[f].values))\n",
    "        test[f] = lbl.transform(list(test[f].values))\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "#brute force scan for all parameters, here are the tricks\n",
    "#usually max_depth is 6,7,8\n",
    "#learning rate is around 0.05, but small changes may make big diff\n",
    "#tuning min_child_weight subsample colsample_bytree can have \n",
    "#much fun of fighting against overfit \n",
    "#n_estimators is how many round of boosting\n",
    "#finally, ensemble xgboost with multiple seeds may reduce variance\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate': [0.05], #so called `eta` value\n",
    "              'max_depth': [6],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.8],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [5], #number of trees, change it to 1000 for better results\n",
    "              'missing':[-999],\n",
    "              'seed': [1337]}\n",
    "\n",
    "\n",
    "clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=StratifiedKFold(train['QuoteConversion_Flag'], n_folds=5, shuffle=True), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "clf.fit(train[features], train[\"QuoteConversion_Flag\"])\n",
    "\n",
    "#trust your CV!\n",
    "best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "print('Raw AUC score:', score)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "test_probs = clf.predict_proba(test[features])[:,1]\n",
    "\n",
    "sample = pd.read_csv('../input/sample_submission.csv')\n",
    "sample.QuoteConversion_Flag = test_probs\n",
    "sample.to_csv(\"xgboost_best_parameter_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
